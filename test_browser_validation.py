#!/usr/bin/env python3
"""
Test browser validation on existing dead link results.
"""

import sys
import os
import csv
from typing import List, Tuple, Optional, Dict
from browser_validation import (
    validate_dead_links_with_browser,
    create_browser_validation_report,
    print_browser_validation_summary
)


def load_dead_links_from_csv(csv_filepath: str) -> List[Tuple[str, str, Optional[int]]]:
    """
    Load dead links from a CSV file generated by the main script.
    
    Args:
        csv_filepath: Path to the CSV file
        
    Returns:
        List of (url, status, status_code) tuples
    """
    dead_links = []
    
    try:
        with open(csv_filepath, 'r', encoding='utf-8') as file:
            reader = csv.DictReader(file)
            for row in reader:
                url = row.get('url', '').strip()
                if url:
                    # Extract status code if available
                    status_code = None
                    if 'status_code' in row and row['status_code']:
                        try:
                            status_code = int(row['status_code'])
                        except ValueError:
                            pass
                    
                    dead_links.append((url, 'dead', status_code))
    except FileNotFoundError:
        print(f"❌ CSV file not found: {csv_filepath}")
        return []
    except Exception as e:
        print(f"❌ Error reading CSV file: {e}")
        return []
    
    return dead_links


def validate_existing_dead_links(csv_filepath: str = None, 
                                headless: bool = True,
                                timeout: int = 30,
                                limit: int = None) -> None:
    """
    Validate existing dead links using browser automation.
    
    Args:
        csv_filepath: Path to CSV file with dead links
        headless: Whether to run browser in headless mode
        timeout: Page load timeout in seconds
        limit: Maximum number of links to check (for testing)
    """
    if not csv_filepath:
        # Look for the most recent CSV file in output directory
        output_dir = 'output'
        if os.path.exists(output_dir):
            csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
            if csv_files:
                csv_filepath = os.path.join(output_dir, csv_files[-1])
                print(f"📄 Using most recent CSV file: {csv_filepath}")
            else:
                print("❌ No CSV files found in output directory")
                return
        else:
            print("❌ Output directory not found")
            return
    
    # Load dead links from CSV
    print("🔍 Loading dead links from CSV...")
    dead_links = load_dead_links_from_csv(csv_filepath)
    
    if not dead_links:
        print("❌ No dead links found in CSV file")
        return
    
    print(f"✅ Loaded {len(dead_links)} dead links")
    
    # Limit for testing if specified
    if limit and limit < len(dead_links):
        dead_links = dead_links[:limit]
        print(f"🔍 Limited to first {limit} links for testing")
    
    # Validate with browser
    print(f"\n🔍 Validating {len(dead_links)} links with browser...")
    print(f"⏱️  Timeout: {timeout}s, Headless: {headless}")
    
    browser_results = validate_dead_links_with_browser(
        dead_links, 
        headless=headless, 
        timeout=timeout
    )
    
    # Create and print report
    report = create_browser_validation_report(dead_links, browser_results)
    print_browser_validation_summary(report)
    
    # Save detailed results
    save_browser_validation_results(dead_links, browser_results, report)


def save_browser_validation_results(dead_links: List[Tuple[str, str, Optional[int]]],
                                  browser_results: List[Tuple[str, str, Optional[int], Dict]],
                                  report: Dict):
    """
    Save browser validation results to a file.
    
    Args:
        dead_links: Original dead link results
        browser_results: Browser validation results
        report: Validation report
    """
    output_file = 'browser_validation_results.txt'
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("Browser Validation Results\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"Summary:\n")
        f.write(f"- Total checked: {report['total_checked']}\n")
        f.write(f"- False positives: {report['false_positives']}\n")
        f.write(f"- Confirmed dead: {report['confirmed_dead']}\n")
        f.write(f"- Blocked: {report['blocked']}\n")
        f.write(f"- Timeout: {report['timeout']}\n")
        f.write(f"- Error: {report['error']}\n\n")
        
        f.write("Detailed Results:\n")
        f.write("-" * 50 + "\n")
        
        for i, (url, initial_status, initial_code) in enumerate(dead_links):
            if i < len(browser_results):
                browser_result = browser_results[i]
                browser_url, browser_status, browser_code, browser_info = browser_result
                
                f.write(f"\nURL: {url}\n")
                f.write(f"Initial Status: {initial_status} (Code: {initial_code})\n")
                f.write(f"Browser Status: {browser_status} (Code: {browser_code})\n")
                
                if browser_info:
                    f.write("Browser Info:\n")
                    for key, value in browser_info.items():
                        f.write(f"  {key}: {value}\n")
                
                f.write("-" * 30 + "\n")
    
    print(f"\n📄 Detailed results saved to: {output_file}")


def test_specific_urls():
    """Test browser validation on specific URLs."""
    
    test_urls = [
        ("https://example.com", "dead", None),  # Should be alive
        ("https://google.com", "dead", None),   # Should be alive
        ("https://github.com", "dead", None),   # Should be alive
        ("https://nonexistentdomain12345.com", "dead", None),  # Should be dead
        ("https://httpbin.org/status/404", "dead", 404),  # Should be dead
        ("https://httpbin.org/status/500", "dead", 500)   # Should be dead
    ]
    
    print("🔍 Testing browser validation on specific URLs...")
    print(f"⏱️  Testing {len(test_urls)} URLs")
    
    browser_results = validate_dead_links_with_browser(
        test_urls,
        headless=True,
        timeout=15
    )
    
    report = create_browser_validation_report(test_urls, browser_results)
    print_browser_validation_summary(report)


def main():
    """Main function."""
    import argparse
    
    parser = argparse.ArgumentParser(description='Validate dead links using browser automation')
    parser.add_argument('--csv-file', type=str, help='Path to CSV file with dead links')
    parser.add_argument('--headless', action='store_true', default=True, 
                       help='Run browser in headless mode (default: True)')
    parser.add_argument('--no-headless', action='store_true', 
                       help='Run browser in visible mode')
    parser.add_argument('--timeout', type=int, default=30,
                       help='Page load timeout in seconds (default: 30)')
    parser.add_argument('--limit', type=int, help='Maximum number of links to check (for testing)')
    parser.add_argument('--test-urls', action='store_true',
                       help='Test with specific URLs instead of CSV file')
    
    args = parser.parse_args()
    
    # Handle headless mode
    headless = args.headless and not args.no_headless
    
    print("🔍 Browser Validation for Dead Links")
    print("=" * 40)
    print(f"⏱️  Timeout: {args.timeout}s")
    print(f"🖥️  Headless: {headless}")
    if args.limit:
        print(f"🔍 Limit: {args.limit} links")
    print()
    
    if args.test_urls:
        test_specific_urls()
    else:
        validate_existing_dead_links(
            csv_filepath=args.csv_file,
            headless=headless,
            timeout=args.timeout,
            limit=args.limit
        )


if __name__ == "__main__":
    main() 